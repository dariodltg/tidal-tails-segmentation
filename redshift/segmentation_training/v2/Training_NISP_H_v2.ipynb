{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b9c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26c8ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "from astropy.io import fits\n",
    "from comet_ml import Experiment\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset\n",
    "from torchmetrics import Dice\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baaa968",
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametros = {'nombre_notebook': 'Training_NISP_H_1000imgs_v2.ipynb',\n",
    "                    'nombre_experimento' : 'Training_NISP_H_1000imgs_v2',\n",
    "                    'nombre_mejor_modelo_a_guardar' : 'NISP_H_1000imgs_v2',\n",
    "                    'device' : torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                    'ruta_galaxias' : 'galaxies_train_NISP_H/galaxy_and_stream_convolved*',\n",
    "                    'ruta_mascaras' : '../masks_NISP_H/mask_',\n",
    "                    'ruta_galaxias_test' : 'galaxies_test_NISP_H/galaxy_and_stream_convolved*.fits',\n",
    "                    'ruta_mascaras_test' : '../masks_NISP_H/mask_',\n",
    "                    'ancho_imagen_original' : 200,\n",
    "                    'alto_imagen_original' : 200,\n",
    "                    'ancho_imagen_deseado' : 224,\n",
    "                    'alto_imagen_deseado' : 224,\n",
    "                    'epocas' : 500,\n",
    "                    'lr' : 1e-3,\n",
    "                    'regularizacion_ridge' : 1e-5,\n",
    "                    'torch seed model weights' : 10,\n",
    "                    'batch_size' : 4,\n",
    "                    'loss' : torch.nn.CrossEntropyLoss()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46b4ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment = Experiment(\n",
    "    api_key=\"dhgO2PK521nSSpRLBYPemvvs7\",\n",
    "    project_name=\"general\",\n",
    "    workspace=\"dario-torre\",\n",
    "    \n",
    ")\n",
    "experiment.set_name(hiperparametros['nombre_experimento'])\n",
    "experiment.log_parameters(hiperparametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = hiperparametros['device']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d56ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_galaxy_number(galaxy_name:str):\n",
    "    return os.path.basename(galaxy_name).split('_')[4]\n",
    "\n",
    "def get_galaxy_magnitude(galaxy_name:str):\n",
    "    return os.path.basename(galaxy_name).split('_')[5]\n",
    "\n",
    "def normalize_01(inp: np.ndarray):\n",
    "    \"\"\"Squash image input to the value range [0, 1] (no clipping)\"\"\"\n",
    "    inp_out = (inp - np.min(inp)) / np.ptp(inp)\n",
    "    return inp_out\n",
    "\n",
    "def imagen_logaritmica(img: np.ndarray)->np.ndarray:\n",
    "    \"\"\"\n",
    "    Escalamos de forma logarítmica la imagen para aumentar el contraste\n",
    "    \"\"\"\n",
    "    img_log = np.log(img, where=(img!=0))\n",
    "    valor_minimo = np.min(img_log)\n",
    "    np.putmask(img_log, img!=0, img_log+abs(valor_minimo))\n",
    "    return img_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset básico sin ningún tipo de augmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, galaxias_con_colas_de_marea, transform=None):\n",
    "        \"\"\"\n",
    "        Constructor del dataset\n",
    "        @param galaxias_con_colas_de_marea: Lista de rutas a los ficheros que contienen los datos de las galaxias\n",
    "        \"\"\"\n",
    "        self.galaxias_con_colas_de_marea = galaxias_con_colas_de_marea\n",
    "        self.transform=transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #Abrimos la imagen de la galaxia con cola de marea\n",
    "        galaxy_fits = fits.open(self.galaxias_con_colas_de_marea[index])\n",
    "        x = galaxy_fits[0].data.astype(np.float32)\n",
    "        #Abrimos la mascara correspondiente a la imagen\n",
    "        numero_galaxia = get_galaxy_number(self.galaxias_con_colas_de_marea[index])\n",
    "        magnitud_galaxia = get_galaxy_magnitude(self.galaxias_con_colas_de_marea[index])\n",
    "        y = np.array(cv2.imread(hiperparametros['ruta_mascaras']+str(numero_galaxia)+\"_\"+str(magnitud_galaxia)+\".png\",0)).astype(np.float32)\n",
    "        x = imagen_logaritmica(x)\n",
    "        x = normalize_01(x)\n",
    "        # Assuming 'input_item' is your input image\n",
    "        x = cv2.resize(x, (hiperparametros['ancho_imagen_deseado'], hiperparametros['alto_imagen_deseado']))\n",
    "        y = cv2.resize(y, (hiperparametros['ancho_imagen_deseado'], hiperparametros['alto_imagen_deseado']))\n",
    "        if(self.transform is not None):\n",
    "            augmented = self.transform(image=x, mask=y)\n",
    "            x_tensor= augmented[\"image\"]\n",
    "            y_tensor= augmented[\"mask\"].long()\n",
    "        else:\n",
    "            x_tensor = torch.from_numpy(x).float()\n",
    "            x_tensor=torch.unsqueeze(x_tensor, dim=0)\n",
    "            y_tensor = torch.from_numpy(y).long()\n",
    "        \n",
    "        #Hacemos reshape de los tensores\n",
    "        y_tensor=torch.unsqueeze(y_tensor, dim=0)\n",
    "        return x_tensor, y_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Devuelve la longitud del dataset\n",
    "        \"\"\"\n",
    "        return len(self.galaxias_con_colas_de_marea)\n",
    "    \n",
    "class MyDatasetTest(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset básico sin ningún tipo de augmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, galaxias_con_colas_de_marea, transform=None):\n",
    "        \"\"\"\n",
    "        Constructor del dataset\n",
    "        @param galaxias_con_colas_de_marea: Lista de rutas a los ficheros que contienen los datos de las galaxias\n",
    "        \"\"\"\n",
    "        self.galaxias_con_colas_de_marea = galaxias_con_colas_de_marea\n",
    "        self.transform=transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #Abrimos la imagen de la galaxia con cola de marea\n",
    "        galaxy_fits = fits.open(self.galaxias_con_colas_de_marea[index])\n",
    "        x = galaxy_fits[0].data.astype(np.float32)\n",
    "        #Abrimos la mascara correspondiente a la imagen\n",
    "        numero_galaxia = get_galaxy_number(self.galaxias_con_colas_de_marea[index])\n",
    "        magnitud_galaxia = get_galaxy_magnitude(self.galaxias_con_colas_de_marea[index])\n",
    "        y = np.array(cv2.imread(hiperparametros['ruta_mascaras_test']+str(numero_galaxia)+\"_\"+str(magnitud_galaxia)+\".png\",0)).astype(np.float32)\n",
    "        x = imagen_logaritmica(x)\n",
    "        x = normalize_01(x)\n",
    "        # Assuming 'input_item' is your input image\n",
    "        x = cv2.resize(x, (hiperparametros['ancho_imagen_deseado'], hiperparametros['alto_imagen_deseado']))\n",
    "        y = cv2.resize(y, (hiperparametros['ancho_imagen_deseado'], hiperparametros['alto_imagen_deseado']))\n",
    "        if(self.transform is not None):\n",
    "            augmented = self.transform(image=x, mask=y)\n",
    "            x_tensor= augmented[\"image\"]\n",
    "            y_tensor= augmented[\"mask\"].long()\n",
    "        else:\n",
    "            x_tensor = torch.from_numpy(x).float()\n",
    "            x_tensor=torch.unsqueeze(x_tensor, dim=0)\n",
    "            y_tensor = torch.from_numpy(y).long()\n",
    "        \n",
    "        #Hacemos reshape de los tensores\n",
    "        y_tensor=torch.unsqueeze(y_tensor, dim=0)\n",
    "        return x_tensor, y_tensor\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Devuelve la longitud del dataset\n",
    "        \"\"\"\n",
    "        return len(self.galaxias_con_colas_de_marea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a7217",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation = A.Compose([\n",
    "    A.Flip(p=0.8),\n",
    "    #A.Rotate(limit=(-180, 180), border_mode='random', p=0.99), \n",
    "    A.ShiftScaleRotate(shift_limit=0.4, rotate_limit=180, p=0.8),\n",
    "    A.GaussNoise(var_limit=(0.001), mean=(0.04), p=0.99),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfb177b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imagenes_train = glob.glob(hiperparametros['ruta_galaxias'])\n",
    "imagenes_valid = glob.glob(hiperparametros['ruta_galaxias_test'])\n",
    "print(\"Number of train images: \" + str(len(imagenes_train)))\n",
    "print(\"Number of valid images: \" + str(len(imagenes_valid)))\n",
    "dataset_augmentations = MyDataset(imagenes_train, augmentation)\n",
    "train_dataset= ConcatDataset([dataset_augmentations])\n",
    "valid_dataset= MyDatasetTest(imagenes_valid)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=hiperparametros['batch_size'], shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=hiperparametros['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc2c7e",
   "metadata": {},
   "source": [
    "## Creación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c246c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = smp.Unet(\n",
    "    encoder_name=\"resnet18\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2,                      # model output channels (number of classes in your dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc070f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(hiperparametros['torch seed model weights'])\n",
    "unet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37708372",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Imprimimos la arquitectura de la red\n",
    "summary(unet, (1, 608, 608))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280e05c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Comprobamos que hemos construido la arquitectura de la red correctamente cargando una imagen del dataset\n",
    "input_item, label_item = train_dataset.__getitem__(0)\n",
    "input_item = input_item.reshape((1,1,hiperparametros['ancho_imagen_deseado'],hiperparametros['alto_imagen_deseado']))\n",
    "label_item = label_item.reshape((1,1,hiperparametros['ancho_imagen_deseado'],hiperparametros['alto_imagen_deseado']))\n",
    "output_item = unet(input_item.to(device)).cpu().detach().squeeze()\n",
    "print(output_item.shape)\n",
    "out_softmax = torch.softmax(output_item, dim=0)\n",
    "mascara_predicha = torch.argmax(out_softmax, dim=0).numpy()\n",
    "fig, (axs0, axs1) = plt.subplots(1,2, figsize = (15,15))\n",
    "axs0.imshow(input_item.squeeze(), interpolation='none', origin=\"lower\")\n",
    "axs1.imshow(label_item.squeeze(), interpolation='none', origin=\"lower\")\n",
    "#plt.imshow(mascara_predicha, interpolation='none', origin=\"lower\")\n",
    "#plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9bd825",
   "metadata": {},
   "source": [
    "## Bucle de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42030d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterio_loss = hiperparametros['loss']\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr=hiperparametros['lr'], weight_decay = hiperparametros['regularizacion_ridge'])\n",
    "mejor_modelo = None\n",
    "mejor_loss = 100000000\n",
    "#Inicializamos la métrica de Dice\n",
    "dice = Dice(num_classes=2, average='macro', ignore_index=0)\n",
    "dice.cuda()\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "train_dice_list = []\n",
    "valid_dice_list = []\n",
    "for epoch in range(hiperparametros['epocas']):\n",
    "    experiment.set_epoch(epoch)\n",
    "    #Parte de train\n",
    "    loss_medio_train = 0\n",
    "    dice_medio_train=0\n",
    "    pasos_train = 0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = unet(inputs)\n",
    "        targets = torch.squeeze(labels, dim=1).type(torch.LongTensor).to(device)\n",
    "        loss = criterio_loss(outputs, targets)\n",
    "        valor_dice = dice(outputs, targets)\n",
    "        loss_medio_train += loss.item()\n",
    "        dice_medio_train += valor_dice.item()\n",
    "        pasos_train += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    experiment.log_metric('Loss train', loss_medio_train/pasos_train)\n",
    "    experiment.log_metric('Dice train', dice_medio_train/pasos_train)\n",
    "    unet.eval()\n",
    "    \n",
    "    #Parte de validacion\n",
    "    loss_medio_valid = 0\n",
    "    dice_medio_valid = 0\n",
    "    pasos_valid = 0\n",
    "    \n",
    "    for i, data in enumerate(valid_dataloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = unet(inputs)\n",
    "        targets = torch.squeeze(labels, dim=1).type(torch.LongTensor).to(device)        \n",
    "        loss = criterio_loss(outputs, targets)\n",
    "        valor_dice = dice(outputs, targets)\n",
    "        loss_medio_valid += loss.item()\n",
    "        dice_medio_valid += valor_dice.item()\n",
    "        pasos_valid += 1\n",
    "    experiment.log_metric('Loss valid', loss_medio_valid/pasos_valid)\n",
    "    experiment.log_metric('Dice valid', dice_medio_valid/pasos_valid)\n",
    "    #Resultados del epoch\n",
    "    print(\"Época: \"+ str(epoch) +\": Loss_train:\"+ str(loss_medio_train/pasos_train)+\" Loss_valid:\"+str(loss_medio_valid/pasos_valid)+ \"\\n Dice_train: \"+ str(dice_medio_train/pasos_train)+ \" Dice_valid: \"+str(dice_medio_valid/pasos_valid))\n",
    "    train_loss_list.append(loss_medio_train/pasos_train)\n",
    "    valid_loss_list.append(loss_medio_valid/pasos_valid)\n",
    "    if (loss_medio_valid/pasos_valid) < mejor_loss:\n",
    "        mejor_modelo = copy.deepcopy(unet)\n",
    "        mejor_loss = loss_medio_valid/pasos_valid\n",
    "    unet.train()\n",
    "print('\\n\\nFinished Training')\n",
    "print('Mejor loss sobre validación alcanzado:', mejor_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mejor_modelo.state_dict(), hiperparametros['nombre_mejor_modelo_a_guardar'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4501255",
   "metadata": {},
   "source": [
    "## Comprobar resultados con el conjunto de train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eba29e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ancho = hiperparametros['ancho_imagen_deseado']\n",
    "alto =hiperparametros['alto_imagen_deseado']\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "mejor_modelo.eval()\n",
    "for i in range(int(len(train_dataset)*0.01)):\n",
    "    item_dataset = train_dataset.__getitem__(i)\n",
    "    item_x = item_dataset[0].reshape((1,1,ancho,alto)).cpu().detach().squeeze().numpy()\n",
    "    item_label = item_dataset[1].reshape((1,1,ancho,alto)).cpu().detach().squeeze().numpy()\n",
    "    #Obtenemos predicción de la red\n",
    "    prediccion_item_tensor = mejor_modelo(item_dataset[0].reshape((1,1,ancho,alto)).to(device)).cpu().detach().squeeze()\n",
    "    out_softmax = torch.softmax(prediccion_item_tensor, dim=0) #Aplicamos una softmax al final (teoricamente no afecta)\n",
    "    mascara_predicha = torch.argmax(out_softmax, dim=0).numpy()\n",
    "    #Mostramos imagen, mascara y mascara predicha\n",
    "    fig, (axs0, axs1, axs2) = plt.subplots(1,3, figsize = (15,15))    \n",
    "    axs0.imshow(item_x, interpolation='none', origin=\"lower\")\n",
    "    axs1.imshow(item_label, interpolation='none', origin=\"lower\")\n",
    "    axs2.imshow(mascara_predicha, interpolation='none', origin=\"lower\")\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af8d5ad",
   "metadata": {},
   "source": [
    "## Comprobar resultados con el conjunto de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b0aef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ancho = hiperparametros['ancho_imagen_deseado']\n",
    "alto =hiperparametros['alto_imagen_deseado']\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "mejor_modelo.eval()\n",
    "for i in range(int(len(valid_dataset)*0.2)):\n",
    "    item_dataset = valid_dataset.__getitem__(i)\n",
    "    item_x = item_dataset[0].reshape((1,1,ancho,alto)).cpu().detach().squeeze().numpy()\n",
    "    item_label = item_dataset[1].reshape((1,1,ancho,alto)).cpu().detach().squeeze().numpy()\n",
    "    #Obtenemos predicción de la red\n",
    "    prediccion_item_tensor = mejor_modelo(item_dataset[0].reshape((1,1,ancho,alto)).to(device)).cpu().detach().squeeze()\n",
    "    mascara_predicha = torch.argmax(prediccion_item_tensor, dim=0).numpy()\n",
    "    #Mostramos imagen, mascara y mascara predicha\n",
    "    fig, (axs0, axs1, axs2) = plt.subplots(1,3, figsize = (15,15))\n",
    "    axs0.imshow(item_x, interpolation='none', origin=\"lower\")\n",
    "    axs1.imshow(item_label, interpolation='none', origin=\"lower\")\n",
    "    axs2.imshow(mascara_predicha, interpolation='none', origin=\"lower\")\n",
    "    plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b99f000",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9095f70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
